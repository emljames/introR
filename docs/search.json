[
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Before the workshop",
    "section": "",
    "text": "The folder including the data and template script for the workshop can be downloaded from github. Please place this folder somewhere in your directory, and unzip the contents. Do not change any of the file structures (i.e., keep the data in the data folder, and the scripts in the script folder!)."
  },
  {
    "objectID": "setup.html#installation-on-a-university-managed-laptop",
    "href": "setup.html#installation-on-a-university-managed-laptop",
    "title": "Before the workshop",
    "section": "3.1 Installation on a university-managed laptop",
    "text": "3.1 Installation on a university-managed laptop\nIf you are working on a university-managed laptop, you can install R and RStudio from the Software Center (Windows) or Self Service (Mac)."
  },
  {
    "objectID": "setup.html#installation-on-a-personal-device",
    "href": "setup.html#installation-on-a-personal-device",
    "title": "Before the workshop",
    "section": "3.2 Installation on a personal device",
    "text": "3.2 Installation on a personal device\nYou will need to have R and RStudio to installed to follow along with the workshop. R is the programming language itself, whereas RStudio is the user interface for interacting with R. Please make sure your software is up-to-date to avoid issues.\nTo download R:\n\nVisit https://cran.r-project.org/ and click Download R for [Windows/macOS], depending on your operating system\nClick to install the “base” distribution, described as what you want for installing R for the first time\nThen click to download the current version (4.5.1)\nOnce the file has downloaded, click to open it.\nWork through the installation, sticking with all the default options\nAt some point, you might get asked to select a CRAN Mirror, which presents you with a couple of options from the UK. I’m not sure it matters which one you choose, but I always select Bristol!\n\nTo download RStudio:\n\nDownload RStudio Desktop via this link: https://posit.co/download/rstudio-desktop/\nOpen the file once it has downloaded, and again walk through the installer using the default options."
  },
  {
    "objectID": "reproducibility.html",
    "href": "reproducibility.html",
    "title": "Reproducible practices",
    "section": "",
    "text": "1 R is for Reproducibility\nOne of the advantages of conducting your data processing and analysis steps in R is that it can be readily shared on platforms such as the Open Science Framework. Using R has several benefits in this regard:\n\nYou can readily strip any information that you don’t want to share (e.g., Prolific IDs, IP addresses, etc.). Where appropriate, you can easily create more than one version of the dataset for different levels of access.\nAll your data cleaning steps are documented in a transparent and reproducible way.\nR is free and widely used, allowing anyone who has access to your scripts and data to reproduce the results (in theory!).\nYou can annotate your code to communicate your decisions and issues along the way (helpful for others AND future you).\nYou can use R Markdown to create readable output files (see below!). These can be helpful for quicker viewing, for making analyses transparent when you can’t share the data, and creating readable output for those who don’t use R.\n\n\n\n2 Creating annotated output files\n\n\n\nArtwork by @allison_horst\n\n\nToday we have been working in an R Markdown file (.Rmd). This differs from a straight forward R script (.R) in that it integrates regular text, code, and output more efficiently, whereas an .R script interprets everything as code by default — essentially like the grey sections we’ve been typing code in today. There are many people who will always use R Markdown when they use R (or the newer version, Quarto). Some people even use it to write their entire manuscripts in a reproducible way!\nThere are many different features of R Markdown that could form a whole workshop on its own. However, with very few extra bits, we have already created a structured output from today’s work. Here are the features that we set up for you in the template file:\n\nWe used the # symbol in regular text to denote headings and subsections. # marks the level 1 heading, ## level 2, and ### level 3.\nWe set up code chunks, which have several features:\n\nThey start and end with three backticks (```) - located on the keyboard above the tab key, to the left of the 1.\nThe first set of backticks are followed by a set of curly brackets {} containing chunk information. The first most important thing in here is the letter r, to instruct the computer to interpret the code as R code.\nThe second thing we included in the curly brackets is a code chunk label. These follow the same rules as column names (i.e., no spaces!). If we want to create an output file, then every code chunk needs a different label.\nThere several other options for setting up your code chunks (e.g., whether the file prints the code and output), but we haven’t gone into this today.\n\n\nThere are several options for formatting your text in different ways. You can incorporate these directly in the source code, but nowadays there’s a much easier editing option in RStudio. If you click on Visual at the top of the script window, it will bring up a text editor with Word-like features. You can switch back and forth between these two editing styles as needed.\nSo how to we turn that into a nice output file? Well, we try clicking “Knit” at the top of the window! This might be a big ask after today’s short workshop, but let’s try it and see what happens.\n\n\n\n\n\n\nDebugging: Common issues that cause problems\n\n\n\n\nNot having the relevant packages installed\nNot having everything scripted - e.g., if you have loaded data in a different way, then R won’t be able to find it again when it runs your code from scratch.\nHaving unfinished code chunks - if R hits an error along the way, it will stop executing the file. If this happens, you could try commenting out that code section as a temporary solution.\nHaving code chunks with duplicate names\n\n\n\nIf it’s not working at the end of this workshop but you’d like to get it up and running, reach out to us for some support.\n\n\n3 Good practices\nHere are a few key principles for working in R:\n\nCode everything! (as much as you can). This is hard when you are a beginner. Why take an hour to make the stupid line of code work when you could open the file in Excel and delete the column in mere seconds? But future you will be grateful when you have to redownload some data and start again. You only need to figure it out once (ask for support if you need to!), and you’ll be super whizzy in the future.\nNever delete raw data (unless there are GDPR/ethics implications) — keep raw and processed data separate.\nUse sensible names for variables and for objects. This will help to make your code more readable, and avoid mistakes. For example, data_session1 is more informative than data2.\nComment everything! Well, not everything. But document your key steps along the way so that it’s readable. This will help other people to understand your code, and will make it easier for future-you to return to.\nChunk your data processing and analysis steps for readability - either in separate files, and/or using features in R Markdown.\nTry to document package versions. One downside to R’s updating and ongoing work is that packages and functions can change, meaning that your code is not entirely future proof. There are some elegant ways to incorporate version control in your scripts, but a simple way to document this you can include a call to sessionInfo() at the end of your .Rmd script.\n\nRemember, a benefit of openness is that you can look to others for examples! The Open Science Framework is ideal for this. Of course there is a lot of variability in coding practices, but looking at how other people go about structuring and reporting their analyses can be a good way to learn. There’s no one right way, so you can decide what you think works well for your particular situation.\n\n\n4 The final word\nFinally, just do the best you can! It’s all well and good to have standards to aim for, but starting out in R can be hard. You can guarantee that our early scripts didn’t look anywhere near our versions now, and that’s OK! R is hard, but it’s also kind of fun.\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "York Psychology ECR Workshop\n— Introduction to R\n",
    "section": "",
    "text": "1 Overview\nThis introductory R workshop has been put together for the York Psychology ECR Forum. The 2025 workshop will take place as follows:\n\nTime and date: 2pm-4pm, Wednesday 29th October\nLocation: Psychology PC Lab (PS/A/203)\nAll welcome\n\nThe session will provide an introduction to R, providing you with the basic skills for getting started in using R for your own research. We will prioritise skills for data wrangling using a set of tools referred to as the tidyverse. The course is aimed at complete beginners in R – no programming experience or prior knowledge of R is required.\nThe workshop will be led by Emma James, with support from Jamie Cockcroft. Both Emma and Jamie use R regularly in their research, and are experienced in supporting learners without any programming backgrounds.\n\n\n\nArtwork by @allison_horst\n\n\n\n\n2 Before the workshop\nBefore the workshop, please follow all the set-up steps on the set-up page.\n\n\n3 Workshop content\nThe main aim of this workshop is to introduce you to some key data processing tools that showcase why R can be an excellent choice for your data analysis. In doing so, we hope to give you the motivation to invest time in developing your skills in R, and the confidence to do so.\nIn this workshop, we will walk through four main sections:\n\nNavigating R\n\nWhy R and RStudio\nRStudio panes\nObjects\nFunctions and packages\n\nCleaning data in R\n\nSelect relevant variables\nRename variables\nFilter for relevant data\n\nTransforming data in R\n\nCalculate participant averages\nCreate new variables\nSaving datasets\n\nReproducible research practices\n\nThe benefits of coding\nAlways comment your code!\nUsing R Markdown for readable outputs\n\n\nThis is quite an ambitious amount to achieve in two hours! It’s fairly likely that we will not get through everything, but we have deliberately left it flexible to adapt to attendees on the day. The materials are written so that you should be able to work through them independently at a later stage. You can also find some suggested resources for further learning.\n\n\n4 During the workshop\n\n4.0.1 Workshop format\nThis is a “live coding” style workshop: Emma will walk through the content step-by-step for attendees to follow along on their own computers. Independent exercises provide opportunities to apply this knowledge, and allow us to re-group if people have fallen behind.\n\n\n4.0.2 Ask for help when you need it\nThis is an informal setting, so please raise your hand whenever you have questions or need something explaining differently. Many aspects of working in R are not obvious when you encounter them for the first time, so no question is too silly to ask!\nJamie will come to your rescue if you fall behind or something isn’t working as expected, and we will pause to get everyone back on track as needed.\n\n\n4.0.3 Sticky notes\nYou should have two coloured sticky notes. Please use these as instructed to indicate when you have finished an exercise, or have fallen behind and need us to slow down.\n\n\n4.0.4 Code of conduct\nWe are all learners at this workshop. Please respect that others might require a slower pace to you (you can always multi-task a little if you’re ahead of the game!). We expect all instructors and attendees to be welcoming and inclusive, and respect each other’s progress at all times. If you believe someone is violating this code of conduct, please let us know so that we can take the appropriate action to address the situation.\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data cleaning in R",
    "section": "",
    "text": "In this section of the workshop, we will learn how to manipulate your data in R. Being able to process and reformat your data in a fast and reproducible way is a major benefit of working in R relative to e.g., Excel and SPSS. We will use a set of functions dedicated to this purpose, known as the tidyverse. In this section, we will refine our dataset based on the variables and observations that we actually need."
  },
  {
    "objectID": "data_cleaning.html#load-packages",
    "href": "data_cleaning.html#load-packages",
    "title": "Data cleaning in R",
    "section": "1.1 Load packages",
    "text": "1.1 Load packages\n(If you’re following this material directly after the Navigating R content, then you’ve already done this first step!)\nWe need to load a collection of functions from the tidyverse. If you have not already installed this package, you still need to run install.packages(\"tidyverse\") in the Console first.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "data_cleaning.html#load-data",
    "href": "data_cleaning.html#load-data",
    "title": "Data cleaning in R",
    "section": "1.2 Load data",
    "text": "1.2 Load data\nWe will be working with data collected from a study of sleep and word learning in children (James, Gaskell, & Henderson, 2020). The experiment involved teaching children the names of unusual plants/animals, and testing their memory for them after periods of wake and sleep. For this lesson, we will analyse the data from the picture naming task, in which children were asked to name pictures of the items as quickly as they could. We will focus on data from the first two test sessions only (12-hour period containing wake or sleep).\nThe folder circulated included folder with the data in it, so we need to instruct R to navigate to the correct file within the raw data folder. If you look in the files pane, you should see that we are currently located in the scripts folder. To navigate to the data folder, we need to include “../” in the file path to instruct R to go “up one level”, then “data/” to go into the data folder, “raw/” to go into the raw data folder, then the file name (including path extension).\nLet’s read in the picture naming file, and assign it to the object “raw_dat”. Remember, the &lt;- means that the action to the right is assigned to the “object” name on the left.\n\nraw_dat &lt;- read_csv(\"../data/raw/picName_raw.csv\")\n\nYou should now see an object named raw_dat in the environment pane, on the top right of your RStudio window. You can see that it has 6602 observations (rows) for 9 variables (columns). You can inspect this by click on the little grid icon next to it.\nWe can also inspect the data format by calling summary() to preview the data, and using the head() function to print the first few rows. Run these lines of code and inspect the output.\n\n# Print summary of variables\nsummary(raw_dat)\n\n# Print first rows of dataset \nhead(raw_dat)\n\nYou don’t need to worry too much about what these different variables mean for the purposes of this workshop, but you can see here that this is trial level data. The dependent variables are accuracy and RT, and we have these across several items for each participant. A full data dictionary is described below."
  },
  {
    "objectID": "data_cleaning.html#data-dictionary",
    "href": "data_cleaning.html#data-dictionary",
    "title": "Data cleaning in R",
    "section": "1.3 Data dictionary",
    "text": "1.3 Data dictionary\n\nID — a unique anonymised code for each participant\ngroup — whether participants were good comprehenders (GC) or poor comprehenders (PC)\ntask — which task this data comes from (all PNN)\nweek — whether participants completed this learnTime condition in the first or second week (counterbalanced)\nlearnTime — whether participants learned the items in the morning (AM) or evening (PM). This was a repeated measures manipulation—all participants completed both a morning and evening condition to compare sleep and wake effects on memory.\ntime — whether the data are from test 1 (immediately after learning), test 2 (12 hours later), test 3 (24 hours later), or test 4 (one month later)\nitem — the word trained and tested\nacc — whether the participant successfully recalled the word in the picture naming task\nRT — response time (ms), for accurate responses only\n\nWe don’t necessarily need everything here, so let’s start wrangling!"
  },
  {
    "objectID": "data_transformation.html",
    "href": "data_transformation.html",
    "title": "Data transformation in R",
    "section": "",
    "text": "So far, we’ve learned how to extract the data that we want to work with in a reproducible and efficient way. But what if we don’t yet have the variables that we want to analyse? The tidyverse has solutions for us there too, where the benefits of the pipe operator (|&gt;) really come into their own. Here we’ll cover how to calculate average participant scores from your raw trial-level data, and how to create new variables based on existing ones."
  },
  {
    "objectID": "data_transformation.html#combining-data-processing-steps",
    "href": "data_transformation.html#combining-data-processing-steps",
    "title": "Data transformation in R",
    "section": "3.1 Combining data processing steps",
    "text": "3.1 Combining data processing steps\nToday we have learned how to load data, select and rename relevant variables, filter out irrelevant cases, and summarise across participants/variables.\nAs a final exercise, let’s create a processed dataset that can show us whether windows of sleep or wake are better for picture naming.\n\n\n\n\n\n\nEXERCISE 5\n\n\n\nCreate a dataset called sleep_wake by chaining the following steps together:\n\nTake the raw data\nInclude only ID, learnTime, time, acc, and RT (renaming if you choose)\nSubset the data to include the first two test times only\nCreate a log-transformed RT variable (log_RT), by using the log() function on RT\nGroup by ID, learnTime and time to calculate average accuracies, raw RTs and log-RTs (i.e., for each participant for each condition)\n\nOnce you have done this, print the whole group summaries by learnTime and time. How does performance change between time 1 and 2 when participants learn in the PM versus the AM?\n\n\n\n\nShow solution\n# Create dataset of participant means \nsleep_wake &lt;- raw_dat |&gt; \n  select(ID, learnTime, time, acc, RT) |&gt; \n  filter(time == 1 | time == 2) |&gt; \n  mutate(log_RT = log(RT)) |&gt; \n  group_by(ID, learnTime, time) |&gt; \n  summarise(acc = mean(acc), RT = mean(RT, na.rm = TRUE), \n            log_RT = mean(log_RT, na.rm = TRUE))\n\n# Group summary statistics\nsleep_wake |&gt; \n  group_by(learnTime, time) |&gt; \n  summarise(mean_acc = mean(acc), mean_RT = mean(RT, na.rm = TRUE), \n            mean_logRT = mean(log_RT, na.rm = TRUE))"
  },
  {
    "objectID": "data_transformation.html#saving-datasets",
    "href": "data_transformation.html#saving-datasets",
    "title": "Data transformation in R",
    "section": "3.2 Saving datasets",
    "text": "3.2 Saving datasets\nWe’ve now created a tidied dataset of participant averages for the variables of interest. In some cases, it might make sense to save this processed dataset so that we don’t have to re-run this script each time, and so that we have a shareable data file.\nIt’s good practice to save your raw and processed data in separate folders, and choosing a file name that clarifies that it’s the processed version. We can use the write_csv() function to do this, which requires the name of the dataframe you want to save and the file path you want to save it to (here specifying how to navigate to the correct folder, and including the file extension).\n\nwrite_csv(sleep_wake, \"../data/processed/picName_processed.csv\")"
  },
  {
    "objectID": "navigating_R.html",
    "href": "navigating_R.html",
    "title": "Navigating R and RStudio",
    "section": "",
    "text": "R is a widely used, free software environment geared towards running statistical analyses. It’s a programming language, and so is often considered to have a steeper learning curve than programs like SPSS. It requires you to learn how to type specific instructions to tell the computer what to do, rather than navigate through menus in a pointy-clicky way. However, this effort is rewarded by greater flexibility, efficiency, and reproducibility in your data analysis.\nObviously we’re here in an R workshop so may be biased, but here are a few of the reasons why R is worth your time:\n\nIt’s free! This means you can take your snazzy analysis skills wherever you want, without requiring someone to pay an expensive software licence.\nIt has a strong online community: there are lots of free online resources to help you with all sorts of data tasks, and highly productive help forums.\nIt’s highly efficient and allows you to manipulate and analyse large datasets with ease.\nYou can more readily make your data processing and analysis reproducible and transparent. By scripting all of your steps, you have a clear record of what you’ve done. This makes it readily shareable with collaborators, other researchers, and (perhaps most importantly) future you.\nThere are many advanced and powerful statistical tools being developed all the time (supply and demand).\nYou’re not restricted to those methods - you can code anything you want!\n\n\n\n\nRStudio is a freeware environment with many helpful features for using R. Most people will use R within the RStudio environment, but you do need to install both R and RStudio separately. In the next section, we’ll introduce the core aspects of the RStudio environment in introducing basic principles."
  },
  {
    "objectID": "navigating_R.html#why-r",
    "href": "navigating_R.html#why-r",
    "title": "Navigating R and RStudio",
    "section": "",
    "text": "R is a widely used, free software environment geared towards running statistical analyses. It’s a programming language, and so is often considered to have a steeper learning curve than programs like SPSS. It requires you to learn how to type specific instructions to tell the computer what to do, rather than navigate through menus in a pointy-clicky way. However, this effort is rewarded by greater flexibility, efficiency, and reproducibility in your data analysis.\nObviously we’re here in an R workshop so may be biased, but here are a few of the reasons why R is worth your time:\n\nIt’s free! This means you can take your snazzy analysis skills wherever you want, without requiring someone to pay an expensive software licence.\nIt has a strong online community: there are lots of free online resources to help you with all sorts of data tasks, and highly productive help forums.\nIt’s highly efficient and allows you to manipulate and analyse large datasets with ease.\nYou can more readily make your data processing and analysis reproducible and transparent. By scripting all of your steps, you have a clear record of what you’ve done. This makes it readily shareable with collaborators, other researchers, and (perhaps most importantly) future you.\nThere are many advanced and powerful statistical tools being developed all the time (supply and demand).\nYou’re not restricted to those methods - you can code anything you want!"
  },
  {
    "objectID": "navigating_R.html#whats-rstudio",
    "href": "navigating_R.html#whats-rstudio",
    "title": "Navigating R and RStudio",
    "section": "",
    "text": "RStudio is a freeware environment with many helpful features for using R. Most people will use R within the RStudio environment, but you do need to install both R and RStudio separately. In the next section, we’ll introduce the core aspects of the RStudio environment in introducing basic principles."
  },
  {
    "objectID": "navigating_R.html#top-left-scripts",
    "href": "navigating_R.html#top-left-scripts",
    "title": "Navigating R and RStudio",
    "section": "2.1 Top left: Scripts",
    "text": "2.1 Top left: Scripts\nIn the top left corner are your scripts, now displaying the template script for today. Scripts are like lists of instructions for the computer to follow. You can save them for future reference, and this makes it easy to set up complex analyses without typing them in by hand each time. Today, we will work in an RMarkdown file format which allows us to easily integrate this script with notes. We’ll come back to the distinction between R and RMarkdown at the end of the session."
  },
  {
    "objectID": "navigating_R.html#bottom-left-console",
    "href": "navigating_R.html#bottom-left-console",
    "title": "Navigating R and RStudio",
    "section": "2.2 Bottom left: Console",
    "text": "2.2 Bottom left: Console\nBelow the script in the bottom left corner is the Console. This is where the magic happens! When you run code from your scripts, it sends it to the console for execution, so you will see the code that you have run followed by the output. You can also type instructions into it directly if you don’t want to save them for a later date. For example, try typing 5 + 5 and hitting the return key."
  },
  {
    "objectID": "navigating_R.html#top-right-environment",
    "href": "navigating_R.html#top-right-environment",
    "title": "Navigating R and RStudio",
    "section": "2.3 Top right: Environment",
    "text": "2.3 Top right: Environment\nThe first tab in the top right hand window is the Environment. This is like R’s memory, and shows what information you have stored. We’ll come back to this in the next section."
  },
  {
    "objectID": "navigating_R.html#bottom-right-other-things",
    "href": "navigating_R.html#bottom-right-other-things",
    "title": "Navigating R and RStudio",
    "section": "2.4 Bottom right: Other things!",
    "text": "2.4 Bottom right: Other things!\nThe bottom right window has several sections that can be navigated by clicking on the tabs at the top. Files shows the files in the directory that we are working from, Plots will contain any figures that we create, Packages contains a list of extensions that will enable us to do different types of statistics, and the Help table will show the help pages for a particular function if we ask for them (we’ll do this a lot!)."
  },
  {
    "objectID": "navigating_R.html#functions",
    "href": "navigating_R.html#functions",
    "title": "Navigating R and RStudio",
    "section": "4.1 Functions",
    "text": "4.1 Functions\nData analysis in R can involve typing a lot of instructions. However, most of the time, someone else has created little packages of instructions for us to use called functions. Each function has a name to call, followed by some arguments that it requires you to enter inside the brackets.\nFor example, there are many basic statistical functions built into R already. For example, earlier we created a list of 5 numbers called b. Let’s try finding out some basic statistical properties using the following functions:\n\nmin(b)\nmax(b)\nmean(b)\nmedian(b)\n\nYou’ll see that each one does pretty much what it says on the tin! You can find out more information about a function by googling it, or by typing help(function_name). For example, if we had missing data in our variable, we might need to explicitly say whether we want it to be ignored."
  },
  {
    "objectID": "navigating_R.html#packages",
    "href": "navigating_R.html#packages",
    "title": "Navigating R and RStudio",
    "section": "4.2 Packages",
    "text": "4.2 Packages\nThese example functions are very simple, but there are much more advanced functions for different purposes - be they loading and manipulating data, running analyses, or plotting graphs. Because many of these tools are specialised for different purposes, not everything is loaded automatically in R. Instead, we can access the functions we need by installing and loading specific packages: collections of functions developed for a particular purpose.\nToday we will be using functions from the tidyverse package. However, you can usually use Google to find other packages that will be useful for any particular purpose.\nIf you have followed the set-up instructions for this workshop, you should have already installed the tidyverse package. If not, you can install it now by typing the following line into your console:\n\ninstall.packages(\"tidyverse\")\n\nYou only need to install packages once, so we can type this directly into the console.\nHowever, you need to load relevant packages into RStudio each time you start a new session. It’s good practice to load packages at the top of a script, so that you always start by loading the necessary tools for your analysis. Let’s do this now: in the first grey section of the template file, under “Load packages”, enter the following line of code:\n\nlibrary(tidyverse)\n\nIf you click the green arrow to run the code in the chunk, you’ll see that it sends the line of code to the console, and prints the output. The tidyverse package is actually a collection of smaller packages made by the same team, so the message here tells us that these different packages are loaded."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Beyond the workshop",
    "section": "",
    "text": "Want to know how to do something? Google it. There are many options for help out there, including:\n\nHelp files for particular functions\nOpen source textbooks\nTutorials attached to specific packages\nBespoke tutorials written by random people\nHelp forums - e.g., StackOverflow"
  },
  {
    "objectID": "resources.html#support-from-the-maths-skills-centre",
    "href": "resources.html#support-from-the-maths-skills-centre",
    "title": "Beyond the workshop",
    "section": "5.1 Support from the Maths Skills Centre",
    "text": "5.1 Support from the Maths Skills Centre\nThere are some helpful resources on getting started with R from the University of York’s Maths Skills Centre."
  },
  {
    "objectID": "resources.html#advanced-statistics-modules-psychology",
    "href": "resources.html#advanced-statistics-modules-psychology",
    "title": "Beyond the workshop",
    "section": "5.2 Advanced statistics modules (Psychology)",
    "text": "5.2 Advanced statistics modules (Psychology)\nIf you want to see more of what R can do, you’re welcome to audit the advanced statistics modules that run in the department (Emma and Jamie both teach on these). You can be added to the VLE, and/or attend the timetabled sessions.\nA different variant of the core module runs in both Semester 1 and Semester 2. Both versions involve an introductory lecture to a different statistical approach each week, plus a practical to demonstrate the method in practice. The Semester 1 version is tailored to third year undergraduate students and can be considered “R light” (limited R knowledge assumed, shorter simple practical demonstration); the Semester 2 version is tailored to MSc Data Science students and places more emphasis on applying the method in R.\nThe precise topics covered vary slightly between the two versions of the module, but can include:\n\nMeta-analysis\nMixed effects models\nStochastic methods / bootstrapping\nNonlinear curve fitting\nStructural equation modelling\nMachine learning\nFourier analysis\nBayesian statistics\nItem response theory\nNetwork modelling\n\nPlease contact Emma for more information if you would like to access or attend these sessions."
  }
]